{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook to reduce data from the Nickel Telescope. Be sure to read the notes in between the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "\n",
    "from overscan_subtraction import overscan_subtraction\n",
    "from bias_subtraction import bias_subtraction\n",
    "from dark_subtraction import dark_subtraction\n",
    "from flat_division import flat_division\n",
    "from correct_object_name import correct_object_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction requires the OBJECT names in the raw FITS files (which are set at the time of the observation) to be one of the following:\n",
    "- \"bias\"\n",
    "- \"dark\"\n",
    "- \"dome flat\"\n",
    "- \"sky flat\" (i.e., flats taken of the sky at sunset)\n",
    "- \"focus\"\n",
    "- your target names (can be anything)\n",
    "\n",
    "If you need to correct OBJECT an in FITS headers of any files, do that below. If everything is correct, ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_object(myfiles, \"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to reduce your data. First, get a list of all the raw data files. The name of the directory with the raw data should have format 'YYYY-MM-DD-nickel-raw'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdir = Path(\"C:/Users/allis/Documents/2024-2025_Local/Akamai Internship/pipeline-testing/test-data-05-12/raw\")  # path to directory with raw data\n",
    "rawfiles = [file for file in rawdir.iterdir() if file.is_file()]\n",
    "\n",
    "\n",
    "\n",
    "# rawfiles = [rawdir + '/' + file for file in sorted(os.listdir(rawdir)) if os.path.isfile(os.path.join(rawdir, file))]\n",
    "# rawfiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create processing and reduced directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = rawdir.parent\n",
    "procdir = rawdir.parent / (rawdir.name + \"-proc\")\n",
    "reddir = rawdir.parent / (rawdir.name + \"-reduced\")\n",
    "\n",
    "# print(procdir)\n",
    "# print(reddir)\n",
    "\n",
    "Path.mkdir(procdir, exist_ok=True)\n",
    "Path.mkdir(reddir, exist_ok=True)\n",
    "\n",
    "# rawdir_split = rawdir.split(\"/\")\n",
    "# if rawdir_split[-1] == \"\":\n",
    "#     rootdir = \"/\".join(rawdir_split[:-2])+\"/\"\n",
    "#     datadir = rawdir_split[-2]+\"/\"\n",
    "# else:\n",
    "#     rootdir = \"/\".join(rawdir_split[:-1])+\"/\"\n",
    "#     datadir = rawdir_split[-1]+\"/\"   \n",
    "\n",
    "# datadir_split = datadir.split(\"-\")\n",
    "\n",
    "# procdir = \"-\".join(datadir_split[:4])+\"-proc/\"\n",
    "# reddir = \"-\".join(datadir_split[:4])+\"-red/\"\n",
    "\n",
    "# print(procdir)\n",
    "# print(reddir)\n",
    "\n",
    "# if not os.path.exists(procdir):\n",
    "#     os.makedirs(procdir)\n",
    "# if not os.path.exists(reddir):\n",
    "#     os.makedirs(reddir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do overscan subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Documents\\2024-2025_Local\\Akamai Internship\\pipeline-testing\\test-data-05-12\\raw-proc\\overscan\n"
     ]
    }
   ],
   "source": [
    "overscan_dir = procdir / 'overscan'\n",
    "print(overscan_dir)\n",
    "Path.mkdir(overscan_dir, exist_ok=True)\n",
    "overscan_files = [overscan_dir / (file.stem + '_proc_over' + file.suffix) for file in rawfiles]\n",
    "# print(overscan_files)\n",
    "\n",
    "overscan_subtraction(rawfiles, overscan_files, 'yes')\n",
    "\n",
    "# procdir = rootdir+procdir\n",
    "# [procdir path] + [file name] + [_proc.] + 'fits' (for all files, excluding subdirectories)\n",
    "# procfiles = [procdir + file.split('.')[0] + '_proc.' + file.split('.')[1] \n",
    "#              for file in sorted(os.listdir(rawdir)) \n",
    "#              if os.path.isfile(os.path.join(rawdir, file))]\n",
    "# print(procfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe of all the files we want to continue reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>object</th>\n",
       "      <th>exptime</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file      object  exptime  \\\n",
       "0   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "1   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "2   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "3   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "4   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "..                                                ...         ...      ...   \n",
       "80  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "81  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "82  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "83  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "84  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "\n",
       "   filt  \n",
       "0     B  \n",
       "1     B  \n",
       "2     B  \n",
       "3     B  \n",
       "4     B  \n",
       "..  ...  \n",
       "80    I  \n",
       "81    I  \n",
       "82    I  \n",
       "83    I  \n",
       "84    I  \n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_list = []\n",
    "exptime_list = []\n",
    "filt_list = []\n",
    "\n",
    "for overscan_file in overscan_files:\n",
    "    hdul = fits.open(str(overscan_file))\n",
    "    obj_list.append(hdul[0].header[\"OBJECT\"])\n",
    "    exptime_list.append(hdul[0].header[\"EXPTIME\"])\n",
    "    filt_list.append(hdul[0].header[\"FILTNAM\"])\n",
    "    hdul.close()\n",
    "\n",
    "df_log = pd.DataFrame({\n",
    "    \"file\": overscan_files,\n",
    "    \"object\": obj_list,\n",
    "    \"exptime\": exptime_list,\n",
    "    \"filt\": filt_list\n",
    "    })\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do bias subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Documents\\2024-2025_Local\\Akamai Internship\\pipeline-testing\\test-data-05-12\\raw-proc\\unbias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>object</th>\n",
       "      <th>exptime</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>bias</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...</td>\n",
       "      <td>PG1530+057</td>\n",
       "      <td>60</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file      object  exptime  \\\n",
       "0   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "1   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "2   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "3   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "4   C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...        bias        0   \n",
       "..                                                ...         ...      ...   \n",
       "80  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "81  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "82  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "83  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "84  C:\\Users\\allis\\Documents\\2024-2025_Local\\Akama...  PG1530+057       60   \n",
       "\n",
       "   filt  \n",
       "0     B  \n",
       "1     B  \n",
       "2     B  \n",
       "3     B  \n",
       "4     B  \n",
       "..  ...  \n",
       "80    I  \n",
       "81    I  \n",
       "82    I  \n",
       "83    I  \n",
       "84    I  \n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather all the bias frames\n",
    "biasfiles = list(df_log.file[df_log.object == 'bias'])\n",
    "\n",
    "# average all of them into one\n",
    "biasdata = []\n",
    "for biasfile in biasfiles:\n",
    "    hdul = fits.open(str(biasfile))\n",
    "    biasdata.append(hdul[0].data)\n",
    "    hdul.close()\n",
    "bias = np.stack(biasdata).mean(axis=0)\n",
    "\n",
    "################ what is this? ###################\n",
    "# omit hot column so that it is properly flat-fielded out\n",
    "bias[:,256] = 0\n",
    "\n",
    "# gather all non-bias files in a subdirectory of -proc\n",
    "nonbias_dir = procdir / 'unbias'\n",
    "print(nonbias_dir)\n",
    "Path.mkdir(nonbias_dir, exist_ok=True)\n",
    "\n",
    "nonbias_files_input = list(df_log.file[df_log.object != 'bias'])\n",
    "nonbias_files_output = [nonbias_dir / (file.stem + '_proc_unbias' + file.suffix) for file in nonbias_files_input]\n",
    "\n",
    "\n",
    "# file1 = nonbias_files_input[0]\n",
    "# print(os.path.basename(nonbias_files_input[0]))\n",
    "# dirname, filename = os.path.split(file1)\n",
    "# comp1 = filename.split('_')\n",
    "# comp1[1] = 'bias'+comp1[1]\n",
    "# newfile = os.path.join(dirname, \"_\".join(comp1))\n",
    "# print(newfile)\n",
    "\n",
    "# nonbias_files_output = [newfile] + nonbias_files_input[1:]\n",
    "\n",
    "bias_subtraction(nonbias_files_input, nonbias_files_output, bias)\n",
    "\n",
    "df_log[\"file\"] = [nonbias_dir / (file.stem + '_proc_unbias' + file.suffix) for file in df_log[\"file\"]]\n",
    "df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all overscan subtracted files to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in overscan_files:\n",
    "#     file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dark subtraction.\n",
    "\n",
    "This can usually be skipped, since the Nickel CCD has a very low dark current, but it is included here for the sake of completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'dark' in list(set(obj_list)):\n",
    "#     darkexptimes = list(set(df_log.exptime[df_log.object == 'dark']))\n",
    "#     for darkexptime in darkexptimes:\n",
    "#         # find all files with this exposure time\n",
    "#         darkfiles = list(df_log.file[(df_log.object == 'dark') & (df_log.exptime == darkexptime)])\n",
    "#         flatfiles = list(df_log.file[((df_log.object == 'dome flat') | (df_log.object == 'sky flat')) &\n",
    "#                                      (df_log.exptime == darkexptime)])\n",
    "#         sciencefiles = list(df_log.file[(df_log.object != 'bias') &\n",
    "#                                         (df_log.object != 'dark') &\n",
    "#                                         (df_log.object != 'dome flat') &\n",
    "#                                         (df_log.object != 'sky flat') &\n",
    "#                                         (df_log.object != 'focus') &\n",
    "#                                         (df_log.exptime == darkexptime)])\n",
    "        \n",
    "#         # calculate average dark frame\n",
    "#         if len(darkfiles) > 1:\n",
    "#             darkdata = []\n",
    "#             for darkfile in darkfiles:\n",
    "#                 hdul = fits.open(darkfile)\n",
    "#                 darkdata.append(hdul[0].data)\n",
    "#                 hdul.close()\n",
    "#             dark = np.stack(darkdata).mean(axis=0)\n",
    "#         else:\n",
    "#             hdul = fits.open(darkfile)\n",
    "#             dark = hdul[0].data\n",
    "#             hdul.close()\n",
    "        \n",
    "#         # do dark subtraction\n",
    "#         if len(flatfiles) > 0:\n",
    "#             dark_subtraction(flatfiles, flatfiles, dark)\n",
    "#         if len(sciencefiles) > 0:\n",
    "#             dark_subtraction(sciencefiles, sciencefiles, dark)\n",
    "\n",
    "# else:\n",
    "#     print('No dark frames detected. Skipping dark subtraction.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do flat division.\n",
    "\n",
    "Divide each pixel and then multiply all pixels by the average of the flat frame.\n",
    "\n",
    "If sky (sunset) flats are available, those are used. If they are not available, dome flats are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  943.92957,   627.42957,   712.72955, ..., 15962.13   ,\n",
      "        16296.7295 , 28274.83   ],\n",
      "       [ 2668.6384 ,  1505.0385 ,  1501.3384 , ..., 35980.438  ,\n",
      "        37834.54   , 64598.438  ],\n",
      "       [ 3213.3472 ,  1665.5471 ,  1623.4471 , ..., 36943.645  ,\n",
      "        38954.047  , 64602.746  ],\n",
      "       ...,\n",
      "       [ 1222.0947 ,   569.7948 ,   514.9948 , ..., 10526.694  ,\n",
      "         8934.995  , 14405.295  ],\n",
      "       [ 1167.6449 ,   526.3449 ,   543.3449 , ...,  8339.645  ,\n",
      "         6999.845  , 10711.345  ],\n",
      "       [ 1270.5951 ,   702.89514,   603.1951 , ...,  6892.7954 ,\n",
      "         5866.8955 ,  7835.8955 ]], dtype='>f4'), array([[ 1108.5116 ,   717.01154,   809.3115 , ..., 18332.71   ,\n",
      "        18811.312  , 32446.412  ],\n",
      "       [ 3069.2227 ,  1757.6228 ,  1804.9227 , ..., 42110.023  ,\n",
      "        44005.125  , 64593.023  ],\n",
      "       [ 3617.9338 ,  1865.1338 ,  1856.0338 , ..., 42978.23   ,\n",
      "        44775.633  , 64597.332  ],\n",
      "       ...,\n",
      "       [ 1366.2384 ,   641.9384 ,   585.1384 , ..., 11999.838  ,\n",
      "        10388.139  , 16871.438  ],\n",
      "       [ 1305.7957 ,   598.4956 ,   611.4956 , ...,  9851.796  ,\n",
      "         8049.9956 , 12282.496  ],\n",
      "       [ 1549.7529 ,   796.053  ,   709.35297, ..., 10212.952  ,\n",
      "         8092.053  , 11631.053  ]], dtype='>f4'), array([[  971.9147 ,   670.4147 ,   701.71466, ..., 16230.115  ,\n",
      "        16819.715  , 28616.814  ],\n",
      "       [ 2764.623  ,  1454.0232 ,  1554.3231 , ..., 37082.42   ,\n",
      "        38632.523  , 64599.42   ],\n",
      "       [ 3194.3315 ,  1640.5315 ,  1662.4315 , ..., 37444.63   ,\n",
      "        39096.03   , 64603.73   ],\n",
      "       ...,\n",
      "       [ 1187.8704 ,   573.5703 ,   545.7703 , ..., 10692.47   ,\n",
      "         9179.7705 , 14678.07   ],\n",
      "       [ 1170.4213 ,   540.1213 ,   510.12125, ...,  8634.421  ,\n",
      "         7041.6216 , 10868.121  ],\n",
      "       [ 1292.3723 ,   724.67236,   603.97235, ...,  7106.5723 ,\n",
      "         6044.6724 ,  7861.6724 ]], dtype='>f4')]\n",
      "[array([[ 1562.8436 ,  1024.3436 ,  1113.6437 , ..., 19511.043  ,\n",
      "        20066.645  , 34129.742  ],\n",
      "       [ 4355.575  ,  2510.975  ,  2512.2751 , ..., 43636.375  ,\n",
      "        45992.477  , 64595.375  ],\n",
      "       [ 5203.306  ,  2627.5063 ,  2778.4065 , ..., 44460.605  ,\n",
      "        46735.008  , 64599.707  ],\n",
      "       ...,\n",
      "       [ 2071.5537 ,   917.2537 ,   887.45374, ..., 12409.153  ,\n",
      "        11004.454  , 19162.754  ],\n",
      "       [ 1898.144  ,   915.844  ,   913.844  , ..., 10466.144  ,\n",
      "         9222.344  , 15169.844  ],\n",
      "       [ 2205.1345 ,  1157.4346 ,  1137.7346 , ..., 11651.334  ,\n",
      "         9812.435  , 15362.435  ]], dtype='>f4'), array([[ 1061.7021 ,   722.20215,   834.50214, ..., 13560.902  ,\n",
      "        14070.502  , 23887.602  ],\n",
      "       [ 3076.425  ,  1700.8252 ,  1780.1251 , ..., 30537.225  ,\n",
      "        32122.324  , 63265.227  ],\n",
      "       [ 3608.1482 ,  1834.348  ,  1923.248  , ..., 31157.447  ,\n",
      "        32559.848  , 64614.547  ],\n",
      "       ...,\n",
      "       [ 1428.4939 ,   668.1939 ,   592.3939 , ...,  8775.094  ,\n",
      "         7728.394  , 13564.694  ],\n",
      "       [ 1314.0619 ,   641.76184,   576.76184, ...,  7402.062  ,\n",
      "         6368.262  , 10821.762  ],\n",
      "       [ 1082.0299 ,   580.32996,   556.62994, ...,  5928.23   ,\n",
      "         5061.33   ,  8106.33   ]], dtype='>f4'), array([[  996.0721 ,   651.5721 ,   763.8721 , ..., 12156.272  ,\n",
      "        12360.872  , 21220.973  ],\n",
      "       [ 2677.7937 ,  1478.1938 ,  1589.4938 , ..., 27144.594  ,\n",
      "        28442.693  , 56063.594  ],\n",
      "       [ 3209.5154 ,  1633.7153 ,  1664.6154 , ..., 27544.816  ,\n",
      "        28788.217  , 62853.914  ],\n",
      "       ...,\n",
      "       [ 1236.3082 ,   573.00824,   550.20825, ...,  7706.908  ,\n",
      "         6922.208  , 12043.509  ],\n",
      "       [ 1131.8708 ,   544.57086,   562.57086, ...,  6622.871  ,\n",
      "         5760.0713 ,  9594.571  ],\n",
      "       [ 1343.8336 ,   736.13367,   715.43365, ...,  7443.0337 ,\n",
      "         6179.134  ,  9689.134  ]], dtype='>f4')]\n",
      "[array([[  620.6107 ,   421.11072,   517.4107 , ..., 11206.811  ,\n",
      "        11393.41   , 19806.512  ],\n",
      "       [ 1740.3105 ,   996.71045,  1020.01056, ..., 25686.11   ,\n",
      "        26323.209  , 53415.11   ],\n",
      "       [ 2049.0103 ,  1078.2102 ,  1129.1102 , ..., 25592.31   ,\n",
      "        27349.71   , 59853.41   ],\n",
      "       ...,\n",
      "       [  832.68036,   393.38034,   390.58032, ...,  7594.2803 ,\n",
      "         6576.58   , 10584.881  ],\n",
      "       [  792.22644,   351.9264 ,   354.9264 , ...,  6265.2266 ,\n",
      "         5145.427  ,  7623.927  ],\n",
      "       [  672.17267,   339.47263,   315.77264, ...,  4719.3726 ,\n",
      "         3732.4727 ,  5318.4727 ]], dtype='>f4'), array([[  715.899  ,   479.399  ,   647.699  , ..., 13942.1    ,\n",
      "        14259.699  , 24522.799  ],\n",
      "       [ 2195.5974 ,  1163.9977 ,  1268.2976 , ..., 31701.396  ,\n",
      "        32922.5    , 64603.4    ],\n",
      "       [ 2557.2961 ,  1301.4962 ,  1355.3962 , ..., 32241.596  ,\n",
      "        33741.996  , 64607.695  ],\n",
      "       ...,\n",
      "       [ 1062.0906 ,   478.79068,   482.99066, ...,  9656.69   ,\n",
      "         8200.991  , 12883.291  ],\n",
      "       [  984.64404,   456.34402,   429.34402, ...,  7791.644  ,\n",
      "         6430.844  ,  9619.345  ],\n",
      "       [ 1120.5975 ,   634.8976 ,   498.1976 , ...,  6650.7974 ,\n",
      "         5081.8975 ,  7080.8975 ]], dtype='>f4')]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# use sky flats if available, use dome flats if not\n",
    "if 'sky flat' in list(set(obj_list)):\n",
    "    flattype = 'sky flat'\n",
    "else:\n",
    "    flattype = 'flat'   # modified from 'dome flat' to 'flat' since 05-12-24 data uses different names\n",
    "    \n",
    "flatfilts = list(set(df_log.filt[df_log.object == flattype]))\n",
    "\n",
    "for flatfilt in flatfilts:\n",
    "    # find all the files with this filter\n",
    "    flatfiles = list(df_log.file[(df_log.object == flattype) & (df_log.filt == flatfilt)])\n",
    "    scienceobjects = list(set(df_log.object[(df_log.object != 'bias') &\n",
    "                                            (df_log.object != 'dark') &\n",
    "                                            (df_log.object != 'flat') &    # modified from 'dome flat' to 'flat' for 05-12-24 data\n",
    "                                            (df_log.object != 'sky flat') &\n",
    "                                            (df_log.object != 'focus') &\n",
    "                                            (df_log.filt == flatfilt)]))\n",
    "    \n",
    "    # calculate the average flat frame\n",
    "    if len(flatfiles) > 1:\n",
    "        flatdata = []\n",
    "        for flatfile in flatfiles:\n",
    "            hdul = fits.open(str(flatfile))\n",
    "            flatdata.append(hdul[0].data)\n",
    "            hdul.close()\n",
    "        print(flatdata)\n",
    "        flat = np.stack(flatdata).mean(axis=0)\n",
    "    else:\n",
    "        hdul = fits.open(str(flatfile))\n",
    "        flat = hdul[0].data\n",
    "        hdul.close()\n",
    "        \n",
    "    if len(scienceobjects) > 0:\n",
    "        for scienceobject in scienceobjects:\n",
    "            sciencefiles = list(df_log.file[(df_log.object == scienceobject) &\n",
    "                                            (df_log.filt == flatfilt)])\n",
    "            \n",
    "            # make a new directory for each science target / filter combination\n",
    "            sci_dir = reddir / (scienceobject + '_' + flatfilt)\n",
    "            Path.mkdir(sci_dir, exist_ok=True)\n",
    "            # os.makedirs(rootdir+reddir+thisdir)\n",
    "\n",
    "            # define reduced file names\n",
    "            redfiles = [sci_dir / (file.stem.split('_')[0] + '_red' + file.suffix) for file in sciencefiles]\n",
    "            \n",
    "            # short_sciencefiles = [file.split('/')[-1] for file in sciencefiles]\n",
    "            # framenum = [frame.split('_')[0] for frame in short_sciencefiles]\n",
    "            # redfiles = [rootdir + reddir + thisdir + frame + '_red.fits' for frame in framenum]\n",
    "\n",
    "            # do flat division\n",
    "            if len(sciencefiles) > 0:\n",
    "                flat_division(sciencefiles, redfiles, flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Your reduced images are now ready for your viewing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
